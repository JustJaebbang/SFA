import io
import math
from pathlib import Path

import numpy as np
import pandas as pd
from PIL import Image

import streamlit as st
import torch
import torch.nn as nn
from torchvision import transforms, models


# =========================
# ì„¤ì •
# =========================
# app.py ìƒë‹¨
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent

MODEL_CHECKPOINT_PATH = BASE_DIR / "best_model.pth"
ALIASES_CSV_PATH      = BASE_DIR / "aliases.csv"        # ë˜ëŠ” ì‹¤ì œ íŒŒì¼ëª…
NUTRITION_CSV_PATH    = BASE_DIR / "nutrition.csv"      # ë˜ëŠ” ì‹¤ì œ íŒŒì¼ëª…

IMAGE_SIZE            = 224


# =========================
# ëª¨ë¸ / ì „ì²˜ë¦¬ ìœ í‹¸
# =========================
def build_model(num_classes: int, pretrained: bool = False) -> nn.Module:
    """EfficientNet-B0 ë¶„ë¥˜ê¸° ìƒì„± (ë„¤ê°€ train.py / infer.pyì—ì„œ ì“°ë˜ ê²ƒê³¼ ë™ì¼í•˜ê²Œ)."""
    weights = models.EfficientNet_B0_Weights.DEFAULT if pretrained else None
    model = models.efficientnet_b0(weights=weights)
    in_features = model.classifier[1].in_features
    model.classifier[1] = nn.Linear(in_features, num_classes)
    return model


def get_transform(image_size: int = IMAGE_SIZE):
    return transforms.Compose(
        [
            transforms.Resize((image_size, image_size)),
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225],
            ),
        ]
    )


@st.cache_resource
def load_model_and_classes():
    """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ê³¼ class_names ë¡œë”© (ìºì‹œ)."""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    ckpt = torch.load(MODEL_CHECKPOINT_PATH, map_location=device)
    class_names = ckpt.get("class_names", None)
    if class_names is None:
        raise ValueError("Checkpoint ì— 'class_names' ë¦¬ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    num_classes = len(class_names)
    model = build_model(num_classes=num_classes, pretrained=False)
    model.load_state_dict(ckpt["model_state_dict"])
    model.to(device)
    model.eval()

    return model, class_names, device


def preprocess_image(pil_image: Image.Image) -> torch.Tensor:
    transform = get_transform(IMAGE_SIZE)
    return transform(pil_image).unsqueeze(0)  # (1, C, H, W)


def predict_food(model, device, input_tensor, class_names):
    with torch.no_grad():
        input_tensor = input_tensor.to(device)
        logits = model(input_tensor)
        probs = torch.softmax(logits, dim=1).squeeze(0)
        conf, pred_idx = torch.max(probs, dim=0)

    pred_idx = int(pred_idx.item())
    conf = float(conf.item())
    pred_class = class_names[pred_idx]

    # í™•ë¥  dict (ì›í•˜ë©´ í…Œì´ë¸”ë¡œ í‘œì‹œ ê°€ëŠ¥)
    prob_dict = {class_names[i]: float(probs[i].item()) for i in range(len(class_names))}
    return pred_class, conf, prob_dict


# =========================
# DB ë¡œë”© & ë§¤í•‘ ìœ í‹¸
# =========================
@st.cache_data
def load_metadata():
    aliases = pd.read_csv(ALIASES_CSV_PATH)
    nutrition = pd.read_csv(NUTRITION_CSV_PATH)

    # food_id ê¸°ì¤€ìœ¼ë¡œ nutrition ì¸ë±ìŠ¤ ì„¸íŒ…
    nutrition = nutrition.set_index("food_id")

    return aliases, nutrition


def normalize_label(label: str) -> str:
    """
    ëª¨ë¸ì˜ class_name ê³¼ aliases.normalized ë¥¼ ë§ì¶”ê¸° ìœ„í•œ ê°„ë‹¨í•œ ì •ê·œí™”.
    ë„¤ ìª½ í´ë˜ìŠ¤ ë„¤ì´ë° ê·œì¹™ì— ë§ê²Œ ìˆ˜ì •í•´ë„ ë¨.
    """
    label = label.strip().lower()
    label = label.replace(" ", "_")
    return label


def find_food_id_from_label(pred_label: str, aliases_df: pd.DataFrame) -> str | None:
    """
    ëª¨ë¸ ì˜ˆì¸¡ label(ì˜ˆ: 'bibimbap')ì„ aliases í…Œì´ë¸”ì—ì„œ food_id ë¡œ ë§¤í•‘.
    ìš°ì„  normalized ì»¬ëŸ¼, ì•ˆ ë˜ë©´ alias ì»¬ëŸ¼ì—ì„œ ì°¾ìŒ.
    """
    norm = normalize_label(pred_label)

    # 1) normalized ë¡œ ìš°ì„  ë§¤ì¹­
    row = aliases_df[aliases_df["normalized"] == norm]
    if len(row) == 0:
        # 2) alias ë¡œ fallback
        row = aliases_df[aliases_df["alias"].str.lower() == pred_label.lower()]

    if len(row) == 0:
        return None

    return row.iloc[0]["food_id"]


def scale_nutrition(nutri_row: pd.Series, portion_g: float) -> pd.Series:
    """
    nutrition.csv ëŠ” per_100g ê¸°ì¤€ (serving_g = 100).
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ portion_g ì— ë§ê²Œ ì„ í˜• ìŠ¤ì¼€ì¼ë§.
    """
    base_serving_g = nutri_row["serving_g"]  # ë³´í†µ 100
    factor = portion_g / base_serving_g

    cols_to_scale = ["energy_kcal", "carb_g", "protein_g", "fat_g", "sodium_mg"]
    scaled = nutri_row.copy()
    for c in cols_to_scale:
        scaled[c] = nutri_row[c] * factor

    scaled["portion_g"] = portion_g
    return scaled


# =========================
# Streamlit UI
# =========================
def main():
    st.set_page_config(page_title="Food Nutrition Estimator", page_icon="ğŸ±", layout="centered")

    st.title("ğŸ± ìŒì‹ ì´ë¯¸ì§€ ê¸°ë°˜ ì˜ì–‘ì„±ë¶„ ì¶”ì • ë°ëª¨")
    st.markdown(
        """
        1. ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ë©´ ëª¨ë¸ì´ **ì–´ë–¤ ìŒì‹ì¸ì§€ ë¶„ë¥˜**í•©ë‹ˆë‹¤.  
        2. ì•„ë˜ **ë¶„ëŸ‰ ìŠ¬ë¼ì´ë”**ë¡œ ì˜ˆìƒ ì„­ì·¨ëŸ‰(g)ì„ ì¡°ì ˆí•˜ë©´,  
           ì¤€ë¹„ëœ nutrition DBë¥¼ ì´ìš©í•´ **ì˜ì–‘ì„±ë¶„ ê°’ì„ ì„ í˜• ìŠ¤ì¼€ì¼ë§**í•´ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.
        """
    )

    # ---- ë©”íƒ€ë°ì´í„° / ëª¨ë¸ ë¡œë”© ----
    aliases_df, nutrition_df = load_metadata()
    try:
        model, class_names, device = load_model_and_classes()
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # ---- ì´ë¯¸ì§€ ì—…ë¡œë“œ ----
    uploaded = st.file_uploader(
        "ìŒì‹ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png)",
        type=["jpg", "jpeg", "png"],
    )

    if uploaded is None:
        st.info("ì™¼ìª½ ìƒë‹¨ì— ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸° í‘œì‹œë©ë‹ˆë‹¤.")
        return

    # PIL ì´ë¯¸ì§€ë¡œ ì—´ê¸°
    try:
        pil_image = Image.open(uploaded).convert("RGB")
    except Exception as e:
        st.error(f"ì´ë¯¸ì§€ë¥¼ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    st.image(pil_image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

    # ---- ëª¨ë¸ ì¶”ë¡  ----
    with st.spinner("ì´ë¯¸ì§€ ë¶„ë¥˜ ì¤‘..."):
        input_tensor = preprocess_image(pil_image)
        pred_label, conf, prob_dict = predict_food(model, device, input_tensor, class_names)

    st.subheader("1ï¸âƒ£ ë¶„ë¥˜ ê²°ê³¼")
    st.write(f"**ì˜ˆì¸¡ ìŒì‹:** `{pred_label}`  (ì‹ ë¢°ë„: {conf*100:.1f}%)")

    # ---- food_id ë§¤í•‘ ----
    food_id = find_food_id_from_label(pred_label, aliases_df)
    if food_id is None or food_id not in nutrition_df.index:
        st.warning("ì˜ˆì¸¡ëœ ìŒì‹ì´ nutrition DBì—ì„œ ë§¤ì¹­ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (aliases.csv / nutrition.csv ë§¤í•‘ í™•ì¸ í•„ìš”)")
        return

    nutri_row = nutrition_df.loc[food_id]

    # ---- ì‚¬ìš©ìê°€ ë¶„ëŸ‰ ìŠ¬ë¼ì´ë”ë¡œ ì¡°ì ˆ ----
    st.subheader("2ï¸âƒ£ ì„­ì·¨ëŸ‰ ì„¤ì •")

    default_g = float(nutri_row["serving_g"])  # ë³´í†µ 100g ê¸°ì¤€
    min_g = 50
    max_g = 1000

    portion_g = st.slider(
        "ì˜ˆìƒ ì„­ì·¨ëŸ‰ (g)",
        min_value=min_g,
        max_value=max_g,
        value=int(default_g),
        step=10,
    )

    scaled = scale_nutrition(nutri_row, portion_g)

    # ---- ê²°ê³¼ í‘œì‹œ ----
    st.subheader("3ï¸âƒ£ ì¶”ì • ì˜ì–‘ì„±ë¶„")

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"**ê¸°ì¤€ ì •ë³´**  \n(food_id: `{food_id}`)")
        st.write(f"- ê¸°ì¤€ serving: {nutri_row['serving_name']} ({nutri_row['serving_g']} g)")
        st.write(f"- ë°ì´í„° ì¶œì²˜: {nutri_row['source']} / ì—…ë°ì´íŠ¸: {nutri_row['updated']}")

    with col2:
        st.markdown("**ì‚¬ìš©ì ì„¤ì • ì„­ì·¨ëŸ‰**")
        st.write(f"- ì„­ì·¨ëŸ‰: **{scaled['portion_g']:.0f} g**")

    # ì˜ì–‘ ì„±ë¶„ í…Œì´ë¸”
    result_df = pd.DataFrame(
        {
            "ì˜ì–‘ì„±ë¶„": ["ì—ë„ˆì§€ (kcal)", "íƒ„ìˆ˜í™”ë¬¼ (g)", "ë‹¨ë°±ì§ˆ (g)", "ì§€ë°© (g)", "ë‚˜íŠ¸ë¥¨ (mg)"],
            "ê°’": [
                scaled["energy_kcal"],
                scaled["carb_g"],
                scaled["protein_g"],
                scaled["fat_g"],
                scaled["sodium_mg"],
            ],
        }
    )

    st.table(result_df.style.format({"ê°’": "{:.2f}"}))

    # (ì„ íƒ) í™•ë¥  ìƒìœ„ kê°œë„ ë³´ê³  ì‹¶ë‹¤ë©´:
    with st.expander("ğŸ” ìƒìœ„ ì˜ˆì¸¡ í´ë˜ìŠ¤ / í™•ë¥  ë³´ê¸°"):
        topk = 5
        items = sorted(prob_dict.items(), key=lambda x: x[1], reverse=True)[:topk]
        prob_df = pd.DataFrame(items, columns=["class_name", "probability"])
        st.table(prob_df.style.format({"probability": "{:.3f}"}))


if __name__ == "__main__":
    main()
